Datasets for Periocular Images



UBIRIS V2 - Need to Apply
UBIPR - Got the database
IITD Multispectral (IMP) - Need to apply
MobBio
FRGC face dataset - provides Gender and Ethnicity - Need to apply
CROSS EYED dataset - Applied already
















Hallucinating the Full Face from the Periocular Region via Dimensionally Weighted K-SVD
Periocular Recognition Using Unsupervised Convolutional RBM Feature Learning
Accurate Periocular Recognition under Less Constrained Environment Using Semantics-Assisted Convolutional Neural Network.



How about using a masked dataset to capture only the periocular area and then generate the facial image, the attributes generated using the periocular region could also be used for face generation.





 The CROSS-EYED, [3] - ”Reading Cross-spectrum
Iris/Periocular Dataset,” is a benchmark dataset for the iden-
tification competition presented in BTAS 2016. It is composed of two eyes images in both visible (VIS/RGB) and
NIR. The images are acquired from a distance of around 1.5
m. The images acquired under NIR wavelength have a sin-
gle channel, while the visible spectrum iris images contain
three channels of information. The images present a realis-
tic indoor environment with a realistic illumination condi-
tion, and there are large variations in the ethnicity and eye
color as well as realistic and challenging illumination reflec-
tions. The database is constructed with 120 subjects. Each
subject is composed of two additional folders, one NIR and
one VIS. For each subject, there are eight images (960 left
and 960 right, 1,920 images per spectrum, 3,840 in total),
as demonstrated by 632 males and 328 females images with
18 females subject with visual evidence of make-up. See
Figure 1. [Gender Classification from Multispectral Periocular Images]




UBIPR: This database contains 5,126 left and
5,126 right periocular images from 344 subjects, and simu-
lates less constrained periocular acquisition environment under
visible spectrum. Noticeable amount of images from this
dataset present occlusion, off-angle or illumination variation.
For the experiments, only left periocular images are used.
We employed the same training set of 3,359 images as used
in [9] for model learning. The remaining 1,767 left images are
used for test phase for performance evaluation. This database
is used for open-world experiments and therefore no subjects
are overlapping between the training and test sets. [Improving Periocular Recognition by Explicit Attention to Critical Regions in Deep Neural Network]

UBIPr - 10199 images There were a few images that were not clear and had issues, so we removed those images and we got only 10138
Total Images are 10138: Left eye and right eye folders are separated for each subject. However, there was an overlap of 3 images, which means left eye folder of a subject had a right eye image or vice versa. SO such images hav been discarded. Therefore total number of images is down to 10,135 now. The total number of class folders are 504, out of which, Number of Male folders are 362, Female folders are 142 
Number of left eye and right eyes are equal to 252 each. Based on having equal number of left and right eye, we are assuming number of subjects as 252, therefore males are 181, and females are 71
Images have been taken at 5 distances, so the image sizes (h x w) are (401 x 501),(441 x 561), (501 x 651),(651 x 801), (801 x 1001), There are 3 images for each image size. Therefore each folder has 15 images, if one session. Some of the images have 2 sessions, which means upto 30 images in each folder.
Next we consolidated the left and right eye folder into one folder for that particular subject. This means we now have 252 subject folders. Out of 252, 89 have more than 30 images, which  implies 89 subjects has 2 sessions. Total number of subjects with more than 30 images are 89 and they are ['subj_1', 'subj_100', 'subj_101', 'subj_103', 'subj_113', 'subj_114', 'subj_117', 'subj_118', 'subj_119', 'subj_120', 'subj_122', 'subj_123', 'subj_124', 'subj_127', 'subj_128', 'subj_129', 'subj_130', 'subj_131', 'subj_149', 'subj_155', 'subj_157', 'subj_159', 'subj_160', 'subj_162', 'subj_163', 'subj_165', 'subj_166', 'subj_168', 'subj_172', 'subj_179', 'subj_182', 'subj_183', 'subj_186', 'subj_189', 'subj_190', 'subj_191', 'subj_194', 'subj_195', 'subj_196', 'subj_20', 'subj_201', 'subj_211', 'subj_213', 'subj_217', 'subj_22', 'subj_221', 'subj_222', 'subj_223', 'subj_225', 'subj_226', 'subj_23', 'subj_233', 'subj_234', 'subj_24', 'subj_25', 'subj_251', 'subj_252', 'subj_254', 'subj_255', 'subj_31', 'subj_37', 'subj_4', 'subj_43', 'subj_45', 'subj_46', 'subj_47', 'subj_48', 'subj_5', 'subj_50', 'subj_51', 'subj_52', 'subj_53', 'subj_54', 'subj_55', 'subj_56', 'subj_61', 'subj_63', 'subj_64', 'subj_74', 'subj_75', 'subj_76', 'subj_83', 'subj_86', 'subj_88', 'subj_89', 'subj_92', 'subj_93', 'subj_94', 'subj_95']
 
